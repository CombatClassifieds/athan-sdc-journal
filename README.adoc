= System Design Captstone
:hide-uri-scheme:
:toc: preamble

Cohort: MCSPB-2311

Date: {docdate}

Project: https://github.com/CombatClassifieds/Website

This report provides measured comparisons between different strategies approaching a higher performance implementation of the "Combat Classifieds" project - included in this document are the strategies used,
explanations for the use of those strategies, and measured performance evidence the strategies provided to compare against the baseline implementation. Though this document tries to be precise and not
entertain speculation, there are designated sections for potential effects of certain (hypothetical) decisions as well.

"Combat Classifieds" is a Next.js application with a PostgreSQL back-end. It uses https://node-postgres.com/[pg] as its database binding library, and React.js components which require API-fetched data do so
through `useEffect()` and the fetch API. The baseline implementation does not use https://react.dev/reference/react/Suspense[`<Suspense>`], nor is there caching of database results. Furthermore, there is not
any preparation for horizontal scaling, though the current benchmarking environment (my laptop) wouldn't give deterministic results of Kubernetes cluster benefits -- that initiative, while would be relatively
simple to support, is omitted from this report due to the inability to gain conclusive results.

== Initial Metrics

The first and easiest metric to gain would be the "requests per second" for a particular route of the Next.js server -- we chose to use the https://httpd.apache.org/docs/2.4/programs/ab.html[Apache Benchmark]
tool, with varying numbers of concurrent requests. We will also use this tool to measure the efficiency of our database; where we'll query a "simple" API endpoint that conducts a particular query. Though
benchmarking the database directly would be considered, we're only taking into consideration the binding from the HTTP server to the database, as this is how the application would be delivered.

The second metric we'll see will be through https://developer.mozilla.org/en-US/docs/Web/API/Performance/now[monotonic time differentials in JavaScript] -- we'll measure the time it takes from when the page
is loaded, until when the page is "ready" -- the moment where there's no longer any pending data requests.

The third metric we'll see will be payload size in Bytes for both HTML pages and API endpoints in JSON -- we'll use this to glean potential gains for network latency.

=== Requests per Second

First, we'll start the Next.js server after loading required environment variables and starting the PostgreSQL database:

[source,bash]
----
npm run dev
----

In another shell, we can run `ab` to benchmark the root endpoint:

[source,bash]
----
ab -n 1000 -c 100 http://127.0.0.1:3000/
----

This will start 100 concurrent connections with `127.0.0.1:3000`, and request the root `/` url 1000 times total. For this test, the mean requests per second is `126.32`.

Let's do the same for an api endpoint:

[source,bash]
----
ab -n 1000 -c 100 http://127.0.0.1:3000/api/item/1
----

The result of this benchmark shows a mean requests per second of `80.4`.

=== Time to Load Data

This has been difficult to gain complete quantitative data on, but the attempt I took was to first
log the current time when the parent component renders, then to log the current time when each
constituent child component has fetched its data -- the difference between the first and last logs would be the "loading time".

In this baseline, the current average difference between these time points is about `800` milliseconds.

=== Network Bandwidth

The `/` route has a total payload of `17.27` kB, but the actual delivery is `6.72` kB. This is due to
Next.js automatically using gZip as its compression algorithm.

The `/api/item/1` route has a total payload of `1.78` kB, but transferred `2.03` kB -- the size actually
_increased_ with compression.
